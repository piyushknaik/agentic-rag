{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f8ed10",
   "metadata": {},
   "source": [
    "## Agentic RAG\n",
    "Retrieval agents are helpful when we need the system to decide whether it should look up information from a knowledge base or not.\n",
    "\n",
    "To build a retrieval agent, we just need to allow the language model (LLM) to use a retriever tool that can search and return relevant information when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5108d4c3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's get all required packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0bf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U --quiet langchain langchain-community langchain-groq langchain-core langgraph chromadb sentence-transformers langchain-huggingface huggingface_hub python-dotenv beautifulsoup4 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae990279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc21889",
   "metadata": {},
   "source": [
    "## RETRIEVER\n",
    "Let's create a vector store retriever using the `Chroma` vector store. We will fetch documents from urls array and use the `Chroma` vector store to create a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35522c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348/770961446.py:18: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=model)\n",
      "/workspaces/agentic-rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://www.webmd.com/allergies/allergy-basics\",\n",
    "    \"https://www.webmd.com/arthritis/understanding-arthritis-symptoms\",\n",
    "    \"https://www.webmd.com/cancer/understanding-cancer-basics\",\n",
    "    \"https://www.webmd.com/depression/what-is-depression\",\n",
    "    \"https://www.webmd.com/cold-and-flu/flu-cold-symptoms\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs_list)\n",
    "\n",
    "model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"medical_chroma_db\"\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34997d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template=(\n",
    "        \"You are a medical assistant. Use the context to analyze the user's symptoms.\\n\"\n",
    "        \"Context:\\n{context}\\n\"\n",
    "        \"\\n\"\n",
    "        \"Question: {query}\\n\"\n",
    "        \"\\n\"\n",
    "        \"Return your answer in this format:\\n\"\n",
    "        \"Disease: <diagnosed disease>\\n\"\n",
    "        \"Criticality: <mild | moderate | severe>\\n\"\n",
    "        \"Remedy: <advice or home remedy or consult doctor>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",  \n",
    "    temperature=0,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581d5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the symptoms you've described, I would analyze them as follows:\n",
      "\n",
      "Disease: Flu\n",
      "Criticality: Moderate\n",
      "Remedy: Since you have a fever and body ache, it's likely that you have the flu. I would recommend consulting your doctor for proper diagnosis and treatment. In the meantime, you can try to manage your symptoms with rest, hydration, and over-the-counter medications such as pain relievers and decongestants. However, if your fever lasts more than three days or if you experience severe body aches, it's essential to consult your doctor to rule out any other underlying conditions.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "rag_retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.1})\n",
    "\n",
    "# Ensure the format_docs function is defined\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Ensure the fallback_chain is defined\n",
    "\n",
    "fallback_chain = RunnableLambda(lambda x: \"Sorry, I couldn't find relevant information to answer your query based on the available medical knowledge.\")\n",
    "\n",
    "# Ensure the rag_chain_lcel is defined using the adjusted retriever\n",
    "rag_chain_primary = (\n",
    "    {\"context\": rag_retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_lcel = rag_chain_primary.with_fallbacks([fallback_chain])\n",
    "\n",
    "# Define a medical query that is expected to retrieve relevant documents\n",
    "medical_query_lcel = \"I have a fever and body ache.\"\n",
    "\n",
    "# Invoke the rag_chain_lcel with the medical query and print the response\n",
    "medical_response_lcel = rag_chain_lcel.invoke(medical_query_lcel)\n",
    "print(medical_response_lcel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
